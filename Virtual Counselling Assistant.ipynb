{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4fd4f3e5967f88",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Import all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T15:52:25.543941030Z",
     "start_time": "2024-02-09T15:52:25.444575305Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skopt\n",
    "from IPython.display import display\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN, BorderlineSMOTE, SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from nltk import word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy import sparse\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, balanced_accuracy_score, roc_auc_score, \\\n",
    "    classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from wordcloud import WordCloud\n",
    "from joblib import dump, load\n",
    "import plotly.graph_objects as go\n",
    "from cuml.neighbors import NearestNeighbors as cuNN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880aa6e486ae874f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde65bfac7a2b69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Loads dataset from remote using tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9b636bcfc393248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T15:52:25.602782940Z",
     "start_time": "2024-02-09T15:52:25.508327991Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# splits = ['train', 'test', 'validation']\n",
    "# df_data = pd.DataFrame()\n",
    "# \n",
    "# for split in splits:\n",
    "#     df_data = pd.concat([df_data, tfds.as_dataframe(tfds.load('goemotions', split=split))])\n",
    "# \n",
    "# df_data.reset_index(drop=True, inplace=True)\n",
    "# df_data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c080ad2b48be1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Loads dataset from local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49793573e22cc22c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('data.csv')\n",
    "del df_data[df_data.columns[0]]\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5bab4281284d04",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72516c7f942e91",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(df_data.describe())\n",
    "df_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8277f348de04f75",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_emotion_distribution(y):\n",
    "    # Create a Bar trace\n",
    "    trace = go.Bar(x=y.value_counts().index, y=y.value_counts().values,\n",
    "                   marker=dict(color=y.value_counts().values, colorscale='Viridis'))\n",
    "\n",
    "    # Layout settings\n",
    "    layout = go.Layout(\n",
    "        title=\"Distribution of Emotions in the Dataset\",\n",
    "        xaxis=dict(title=\"Emotions\"),\n",
    "        yaxis=dict(title=\"Count\"),\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    # Create Figure\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Assuming 'y' is a pandas Series\n",
    "y = df_data.drop(['comment_text'], axis=1).idxmax(axis=1)\n",
    "y.name = 'emotion'\n",
    "plot_emotion_distribution(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d9ab9f6a855a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_data['comment_text']\n",
    "wordcloud = WordCloud(background_color='white', width=800, height=800).generate(''.join(X.astype(str)))\n",
    "\n",
    "# Set the size of the figure\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Display the WordCloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45226655d34d100",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e2814ec61a2135",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb864b00287ef762",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Actions performed for text cleaning:\n",
    "- Decode and lowercase\n",
    "- Emoji to text\n",
    "- Remove URL, HTML, Special Characters, Punctuation, Stopwords, Whitespaces and Numbers\n",
    "- Transform Abbreviations\n",
    "- Tokenization\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "254678ac44019ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T15:52:35.741755471Z",
     "start_time": "2024-02-09T15:52:35.665788401Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopword = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    def get_full_form_from_wordnet(abbreviation):\n",
    "        synsets = wordnet.synsets(abbreviation)\n",
    "        if synsets:\n",
    "            return synsets[0].lemmas()[0].name()\n",
    "        else:\n",
    "            return abbreviation\n",
    "\n",
    "    # Decode the text and convert to lowercase\n",
    "    if text.startswith(\"b'\") or text.startswith('b\"'):\n",
    "        try:\n",
    "            # Convert string representation to an actual byte object\n",
    "            text = eval(text)\n",
    "            text = text.decode('utf-8')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # Emoji to text\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \"\"))\n",
    "\n",
    "    # Remove url, html, special char, punct, and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.compile(r'http[s]?://\\S+|www\\.\\S+').sub(r' ', text)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords, transform abbreviations, and stem the tokens\n",
    "    tokens = [word for word in tokens if word not in stopword]\n",
    "    tokens = map(get_full_form_from_wordnet, tokens)\n",
    "    tokens = map(lambda x: stemmer.stem(x), tokens)\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join the lemmatized tokens into a string\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    # Strip to single white space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', lemmatized_text).strip()\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b8c83624b4e75",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preprocess text and reverse encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10fcd9377e12ac1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_data['comment_text'].apply(preprocess_text).to_frame().squeeze()\n",
    "y = df_data.drop(['comment_text'], axis=1).idxmax(axis=1)\n",
    "y.name = 'emotion'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True, random_state=3013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a152a689e84d33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Vectorize Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19d09a4922491c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.232077802Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f1ec6fc32e4de",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71afdee2a732a65",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Functions for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708db44d77229a51",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.232735353Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_resampled_data(X, y, filename_prefix):\n",
    "    sparse.save_npz(f'{filename_prefix}_X.npz', X)\n",
    "    np.save(f'{filename_prefix}_y.npy', y)\n",
    "\n",
    "\n",
    "def evaluate_model(X_train, X_test, y_train, y_test, encoder, classifiers, resamplers=None):\n",
    "    df_performance = pd.DataFrame(\n",
    "        index=['Accuracy', 'Precision', 'Recall', 'F1 score', 'ROC', 'Training Time', 'Testing time'])\n",
    "\n",
    "    if resamplers:\n",
    "\n",
    "        df_resampler = pd.DataFrame(\n",
    "            index=['Resample Time', 'Size'] + list(pd.unique(encoder.inverse_transform(y_train))))\n",
    "        os.makedirs('resampled_data', exist_ok=True)\n",
    "\n",
    "        for spl_name, spl_obj in resamplers:\n",
    "\n",
    "            resampled_data_file_X = os.path.join('resampled_data', f'{spl_name}_resampled_data_X.npz')\n",
    "            resampled_data_file_y = os.path.join('resampled_data', f'{spl_name}_resampled_data_y.npy')\n",
    "\n",
    "            if os.path.exists(resampled_data_file_X) and os.path.exists(resampled_data_file_y):\n",
    "                X_train_resampled, y_train_resampled = sparse.load_npz(resampled_data_file_X), \\\n",
    "                    np.load(resampled_data_file_y, allow_pickle=True)\n",
    "            else:\n",
    "                # Apply resampling and store the results\n",
    "                start_time = time.time()\n",
    "                X_train_resampled, y_train_resampled = spl_obj.fit_resample(X_train, y_train)\n",
    "                resample_time = time.time() - start_time\n",
    "                df_resampler.loc['Resample Time', spl_name] = resample_time\n",
    "                df_resampler.loc['Size', spl_name] = len(y_train_resampled)\n",
    "                for index, value in pd.DataFrame(encoder.inverse_transform(y_train_resampled)).value_counts().items():\n",
    "                    df_resampler.loc[index, spl_name] = value\n",
    "\n",
    "                save_resampled_data(X_train_resampled, y_train_resampled,\n",
    "                                    os.path.join('resampled_data', f'{spl_name}_resampled_data'))\n",
    "\n",
    "            for clf_name, clf in classifiers:\n",
    "                label = f'{spl_name} & {clf_name}'\n",
    "                results = evaluate_performance(X_train_resampled, X_test, y_train_resampled, y_test, encoder,\n",
    "                                               (label, clf))\n",
    "                df_performance[label] = results\n",
    "\n",
    "        return df_resampler, df_performance\n",
    "\n",
    "    else:\n",
    "        for clf_name, clf in classifiers:\n",
    "            results = evaluate_performance(X_train, X_test, y_train, y_test, encoder, (clf_name, clf))\n",
    "            df_performance[clf_name] = results\n",
    "\n",
    "        return df_performance\n",
    "\n",
    "\n",
    "def evaluate_performance(X_train, X_test, y_train, y_test, encoder, clf):\n",
    "    # Training the model\n",
    "    start_time = time.time()\n",
    "    clf[1].fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    start_time = time.time()\n",
    "    predictions = clf[1].predict(X_test)\n",
    "    testing_time = time.time() - start_time\n",
    "    accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "    precision, recall, f1score, support = precision_recall_fscore_support(y_test, predictions,\n",
    "                                                                          average='macro',\n",
    "                                                                          zero_division=0)\n",
    "    roc = roc_auc_score(y_test, clf[1].predict_proba(X_test), average='macro', multi_class='ovr')\n",
    "    print(f'\\n\\n-----------------------{clf[0]} done evaluation.')\n",
    "    print(classification_report(encoder.inverse_transform(y_test), encoder.inverse_transform(predictions),\n",
    "                                zero_division=0))\n",
    "\n",
    "    return [accuracy, precision, recall, f1score, roc, training_time, testing_time]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367c0530bf0eeda",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Encode target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed89ad540d9c95",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.233538110Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(y_train)\n",
    "y_train_encoded = encoder.transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a5058e6bad161",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Classifiers and resamplers involved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7f9c5648ddc73",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.234174120Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resamplers = [\n",
    "    (\n",
    "        'RandomUnderSampler',\n",
    "        RandomUnderSampler(\n",
    "            sampling_strategy='not minority',\n",
    "            random_state=3013)\n",
    "    ),\n",
    "    (\n",
    "        'NearMiss',\n",
    "        NearMiss(\n",
    "            sampling_strategy='not minority',\n",
    "            version=3,\n",
    "            n_jobs=-1)\n",
    "    ),\n",
    "    (\n",
    "        'ADASYN',\n",
    "        ADASYN(\n",
    "            sampling_strategy='minority',\n",
    "            random_state=3013,\n",
    "            n_neighbors=cuNN())\n",
    "    ),\n",
    "    (\n",
    "        'SMOTE',\n",
    "        SMOTE(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013,\n",
    "            k_neighbors=cuNN())\n",
    "    ),\n",
    "    (\n",
    "        'BorderlineSMOTE',\n",
    "        BorderlineSMOTE(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013,\n",
    "            k_neighbors=cuNN(),\n",
    "            m_neighbors=cuNN(n_neighbors=10)))\n",
    "    ,\n",
    "    (\n",
    "        'SMOTETomek',\n",
    "        SMOTETomek(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013,\n",
    "            n_jobs=-1,\n",
    "            smote=SMOTE(k_neighbors=cuNN()))\n",
    "    ),\n",
    "    (\n",
    "        'SMOTEENN',\n",
    "        SMOTEENN(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013,\n",
    "            smote=SMOTE(k_neighbors=cuNN()),\n",
    "            enn=EditedNearestNeighbours(n_neighbors=cuNN()))\n",
    "    ),\n",
    "    (\n",
    "        'RandomOverSampler',\n",
    "        RandomOverSampler(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013)),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        'LGBMClassifier',\n",
    "        LGBMClassifier(\n",
    "            random_state=3013,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            verbose=-1)\n",
    "    ),\n",
    "    (\n",
    "        'SGDLogisticRegression',\n",
    "        SGDClassifier(\n",
    "            random_state=3013,\n",
    "            loss='log_loss', class_weight='balanced',\n",
    "            n_jobs=-1),\n",
    "    ),\n",
    "    (\n",
    "        'SGDLinearSVC',\n",
    "        CalibratedClassifierCV(\n",
    "            SGDClassifier(\n",
    "                random_state=3013,\n",
    "                loss='hinge', class_weight='balanced',\n",
    "                n_jobs=-1),\n",
    "            method='isotonic'),\n",
    "    )\n",
    "]\n",
    "\n",
    "voting_classifier = EnsembleVoteClassifier(clfs=[clf[1] for clf in classifiers],\n",
    "                                           voting='soft',\n",
    "                                           fit_base_estimators=False,\n",
    "                                           use_clones=False)\n",
    "\n",
    "classifiers.append(('Voting Classifier', voting_classifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00efe2071ff557a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### General performance comparison between classifiers and classifiers with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672c6fb06a46f07",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.237292664Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a975e2e1636bf6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.241649223Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_performance_clfs = evaluate_model(X_train_vectorized, X_test_vectorized, y_train_encoded, y_test_encoded, encoder,\n",
    "                                     classifiers)\n",
    "\n",
    "df_performance_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef76894e2b9fa6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.244516589Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_resample, df_performance_reclfs = evaluate_model(X_train_vectorized, X_test_vectorized, y_train_encoded,\n",
    "                                                    y_test_encoded, encoder, classifiers,\n",
    "                                                    resamplers)\n",
    "\n",
    "display(df_resample)\n",
    "df_performance_reclfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cc70c0a6ea742b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### General performance comparison between classifiers and classifiers with resampling after grouping emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c832c8d0867bc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.248071542Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotion_groups = {\n",
    "    \"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
    "    \"disgust\": [\"disgust\"],\n",
    "    \"fear\": [\"fear\", \"nervousness\"],\n",
    "    'neutral': ['neutral'],\n",
    "    \"joy\": [\"admiration\", \"amusement\", \"approval\", \"caring\", \"desire\", \"excitement\", \"gratitude\", \"joy\", \"love\",\n",
    "            \"optimism\", \"pride\", \"relief\"],\n",
    "    \"sadness\": [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\", \"remorse\"],\n",
    "    \"surprise\": [\"confusion\", \"curiosity\", \"realization\", \"surprise\"]\n",
    "}\n",
    "\n",
    "y_train_grouped = y_train.apply(\n",
    "    lambda x: next((group for group, emotions in emotion_groups.items() if x in emotions), x))\n",
    "y_test_grouped = y_test.apply(lambda x: next((group for group, emotions in emotion_groups.items() if x in emotions), x))\n",
    "y_grouped = pd.concat([y_train_grouped, y_test_grouped])\n",
    "plot_emotion_distribution(y_grouped)\n",
    "\n",
    "y_grouped.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895fee759a6a73af",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Encode grouped target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43682c4f5e64ba1c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.252539333Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gp_encoder = LabelEncoder().fit(y_train_grouped)\n",
    "y_gp_train_encoded = gp_encoder.transform(y_train_grouped)\n",
    "y_gp_test_encoded = gp_encoder.transform(y_test_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71ed94631a9b114",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.256372957Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resamplers = [\n",
    "    (\n",
    "        'GP_RandomUnderSampler',\n",
    "        RandomUnderSampler(\n",
    "            sampling_strategy='not minority',\n",
    "            random_state=3013)\n",
    "    ),\n",
    "    (\n",
    "        'GP_NearMiss',\n",
    "        NearMiss(\n",
    "            sampling_strategy='not minority',\n",
    "            version=3,\n",
    "            n_jobs=-1)\n",
    "    ),\n",
    "    (\n",
    "        'GP_ADASYN',\n",
    "        ADASYN(\n",
    "            sampling_strategy='minority',\n",
    "            random_state=3013,\n",
    "            n_neighbors=cuNN())\n",
    "    ),\n",
    "    (\n",
    "        'GP_SMOTE',\n",
    "        SMOTE(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013,\n",
    "            k_neighbors=cuNN())\n",
    "    ),\n",
    "    (\n",
    "        'GP_BorderlineSMOTE',\n",
    "        BorderlineSMOTE(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013,\n",
    "            k_neighbors=cuNN(),\n",
    "            m_neighbors=cuNN(n_neighbors=10)))\n",
    "    ,\n",
    "    (\n",
    "        'GP_SMOTETomek',\n",
    "        SMOTETomek(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013,\n",
    "            n_jobs=-1,\n",
    "            smote=SMOTE(k_neighbors=cuNN()))\n",
    "    ),\n",
    "    (\n",
    "        'GP_SMOTEENN',\n",
    "        SMOTEENN(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013,\n",
    "            smote=SMOTE(k_neighbors=cuNN()),\n",
    "            enn=EditedNearestNeighbours(n_neighbors=cuNN()))\n",
    "    ),\n",
    "    (\n",
    "        'GP_RandomOverSampler',\n",
    "        RandomOverSampler(\n",
    "            sampling_strategy='not majority',\n",
    "            random_state=3013)),\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    (\n",
    "        'GP_LGBMClassifier',\n",
    "        LGBMClassifier(\n",
    "            random_state=3013,\n",
    "            class_weight='balanced',\n",
    "            n_jobs=-1,\n",
    "            verbose=-1)\n",
    "    ),\n",
    "    (\n",
    "        'GP_SGDLogisticRegression',\n",
    "        SGDClassifier(\n",
    "            random_state=3013,\n",
    "            loss='log_loss', class_weight='balanced',\n",
    "            n_jobs=-1)\n",
    "    ),\n",
    "    (\n",
    "        'GP_SGDLinearSVM',\n",
    "        CalibratedClassifierCV(\n",
    "            SGDClassifier(\n",
    "                random_state=3013,\n",
    "                loss='hinge', class_weight='balanced',\n",
    "                n_jobs=-1),\n",
    "            method='isotonic')\n",
    "    )\n",
    "]\n",
    "\n",
    "voting_classifier = EnsembleVoteClassifier(clfs=[clf[1] for clf in classifiers],\n",
    "                                           voting='soft',\n",
    "                                           fit_base_estimators=False)\n",
    "\n",
    "classifiers.append(('Voting Classifier', voting_classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9c5394d4c157c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-09T15:52:51.260200760Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_performance_gp_clfs = evaluate_model(X_train_vectorized, X_test_vectorized, y_gp_train_encoded, y_gp_test_encoded,\n",
    "                                        gp_encoder,\n",
    "                                        classifiers)\n",
    "\n",
    "df_performance_gp_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9125bc451dc58",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_gp_resample, df_performance_gp_reclfs = evaluate_model(X_train_vectorized, X_test_vectorized, y_gp_train_encoded,\n",
    "                                                          y_gp_test_encoded, gp_encoder, classifiers, resamplers)\n",
    "\n",
    "display(df_gp_resample)\n",
    "df_performance_gp_reclfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38774b550a02a224",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Parameter Tuning using BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122d2afc64cbbfa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T14:05:10.994530545Z",
     "start_time": "2024-02-09T14:05:10.062808525Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def searchCV(X_train, y_train, pipeline, params):\n",
    "    bscv = BayesSearchCV(\n",
    "        pipeline[1],\n",
    "        params,\n",
    "        n_iter=100,\n",
    "        n_points=4,\n",
    "        scoring='f1_macro',\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=False),\n",
    "        verbose=0,\n",
    "        n_jobs=3,\n",
    "        pre_dispatch='2*n_jobs',\n",
    "        random_state=3013,\n",
    "        error_score=0,\n",
    "    )\n",
    "\n",
    "    np.int = int\n",
    "    start_time = time.time()\n",
    "    bscv.fit(X_train, y_train)\n",
    "    search_time = time.time() - start_time\n",
    "    best_parameters = bscv.best_params_\n",
    "    display(pd.DataFrame)\n",
    "\n",
    "    clf_name = pipeline[0]\n",
    "    print(f'------------------{clf_name} tuning done.')\n",
    "    print(f'Search time: {search_time}')\n",
    "    print(f'Best parameters: {best_parameters}')\n",
    "    print(f'Best CV score: {bscv.best_score_}')\n",
    "    skopt.dump(bscv, f'tuned_{clf_name}.pkl')\n",
    "\n",
    "    return bscv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f57575d357932b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Required for applying bayes search on ngram_range with skopt as list of tuple is not supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b433f750d6732258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T23:44:43.591994506Z",
     "start_time": "2024-02-08T23:44:43.012393055Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomTfidfVectorizer(TfidfVectorizer):\n",
    "    def __init__(\n",
    "            self,\n",
    "            ngram_lower=1,\n",
    "            ngram_upper=1,\n",
    "            input=\"content\",\n",
    "            encoding=\"utf-8\",\n",
    "            decode_error=\"strict\",\n",
    "            strip_accents=None,\n",
    "            lowercase=True,\n",
    "            preprocessor=None,\n",
    "            tokenizer=None,\n",
    "            analyzer=\"word\",\n",
    "            stop_words=None,\n",
    "            token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "            max_df=1.0,\n",
    "            min_df=1,\n",
    "            max_features=None,\n",
    "            vocabulary=None,\n",
    "            binary=False,\n",
    "            dtype=np.float64,\n",
    "            norm=\"l2\",\n",
    "            use_idf=True,\n",
    "            smooth_idf=True,\n",
    "            sublinear_tf=False,\n",
    "    ):\n",
    "        self.ngram_lower = ngram_lower\n",
    "        self.ngram_upper = ngram_upper\n",
    "        super().__init__(\n",
    "            ngram_range=(ngram_lower, ngram_upper),\n",
    "            input=input,\n",
    "            encoding=encoding,\n",
    "            decode_error=decode_error,\n",
    "            strip_accents=strip_accents,\n",
    "            lowercase=lowercase,\n",
    "            preprocessor=preprocessor,\n",
    "            tokenizer=tokenizer,\n",
    "            analyzer=analyzer,\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=token_pattern,\n",
    "            max_df=max_df,\n",
    "            min_df=min_df,\n",
    "            max_features=max_features,\n",
    "            vocabulary=vocabulary,\n",
    "            binary=binary,\n",
    "            dtype=dtype,\n",
    "            norm=norm,\n",
    "            use_idf=use_idf,\n",
    "            smooth_idf=smooth_idf,\n",
    "            sublinear_tf=sublinear_tf,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3f9d8dbe83021",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The process is carried out on cloud platform, hence the missing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12491562d9ed38de",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid_random_over_sampler = {\n",
    "    'spl': [RandomOverSampler(random_state=3013)],\n",
    "    'spl__sampling_strategy': ['not majority', 'minority'],\n",
    "}\n",
    "\n",
    "param_grid_smote = {\n",
    "    'spl': [SMOTE(random_state=3013, k_neighbors=cuNN())],\n",
    "    'spl__k_neighbors__n_neighbors': Integer(3, 15),\n",
    "    'spl__sampling_strategy': ['not majority', 'minority'],\n",
    "}\n",
    "\n",
    "param_ADASYN = {\n",
    "    'spl': [ADASYN(random_state=3013, n_neighbors=cuNN(), sampling_strategy='minority')],\n",
    "    'spl__n_neighbors__n_neighbors': Integer(3, 15),\n",
    "}\n",
    "\n",
    "param_SGDLR = {\n",
    "    'clf__loss': ['log_loss'],\n",
    "    'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'clf__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'clf__eta0': Real(0.00001, 0.2),\n",
    "    'clf__max_iter': Integer(1000, 5000),\n",
    "    'clf__alpha': Real(0.0001, 0.1),\n",
    "    'clf__l1_ratio': Real(0.1, 0.5),\n",
    "    'clf__class_weight': ['balanced', None],\n",
    "}\n",
    "\n",
    "param_LGBM = {\n",
    "    'clf__max_depth': Integer(5, 50),\n",
    "    'clf__min_child_samples': Integer(20, 100),\n",
    "    'clf__boosting_type': ['gbdt', 'dart', 'rf'],\n",
    "    'clf__learning_rate': Real(0.00001, 0.2),\n",
    "    'clf__n_estimators': Integer(80, 200),\n",
    "    'clf__num_iterations': Integer(100, 500),\n",
    "    'clf__num_leaves': Integer(25, 60),\n",
    "    'clf__bagging_freq': Integer(1, 10),\n",
    "    'clf__bagging_fraction': Real(0.01, 0.99),\n",
    "    'clf__feature_fraction': Real(0.01, 0.99),\n",
    "    'clf__class_weight': ['balanced', None],\n",
    "}\n",
    "\n",
    "param_SGDSVC = {\n",
    "    'clf__estimator__loss': ['hinge'],\n",
    "    'clf__estimator__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'clf__estimator__learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'clf__estimator__eta0': Real(0.00001, 0.2),\n",
    "    'clf__estimator__max_iter': Integer(1000, 5000),\n",
    "    'clf__estimator__alpha': Real(0.0001, 0.1),\n",
    "    'clf__estimator__class_weight': ['balanced', None],\n",
    "    'clf__estimator__l1_ratio': Real(0.1, 0.5),\n",
    "    'clf__method': ['sigmoid', 'isotonic'],\n",
    "    'clf__cv': Integer(2, 10),\n",
    "}\n",
    "\n",
    "pipelines = [\n",
    "    (\n",
    "        param_SGDLR,\n",
    "        ('Logistic Regression', Pipeline([\n",
    "            ('vect', CustomTfidfVectorizer(ngram_lower=1)),\n",
    "            ('spl', RandomOverSampler()),  # Dummy Sampler\n",
    "            ('clf', SGDClassifier(random_state=3013, n_jobs=-1, loss='log_loss')),\n",
    "        ]))\n",
    "    ),\n",
    "    (\n",
    "        param_SGDSVC,\n",
    "        ('Linear SVM', Pipeline([\n",
    "            ('vect', CustomTfidfVectorizer(ngram_lower=1)),\n",
    "            ('spl', RandomOverSampler()),  # Dummy Sampler\n",
    "            ('clf', CalibratedClassifierCV(estimator=SGDClassifier(random_state=3013, n_jobs=-1, loss='hinge'))),\n",
    "        ]))\n",
    "    ),\n",
    "    (\n",
    "        param_LGBM,\n",
    "        ('LGBM Classifier', Pipeline([\n",
    "            ('vect', CustomTfidfVectorizer(ngram_lower=1)),\n",
    "            ('spl', RandomOverSampler()),  # Dummy Sampler\n",
    "            ('clf', LGBMClassifier()),\n",
    "        ]))\n",
    "    ),\n",
    "]\n",
    "\n",
    "cvinstances = []\n",
    "\n",
    "for param, pipeline in pipelines:\n",
    "\n",
    "    param_vectorizer = {\n",
    "        'vect__max_features': Integer(2500, 50000),\n",
    "        'vect__max_df': Real(0.9, 1.0),\n",
    "        'vect__min_df': Real(0.0, 0.1),\n",
    "        'vect__ngram_upper': Integer(1, 3),\n",
    "    }\n",
    "\n",
    "    param_grids = []\n",
    "\n",
    "    for param_oversampler, oversampler_params in [('smote', param_grid_smote),\n",
    "                                                  ('random_over_sampler', param_grid_random_over_sampler),\n",
    "                                                  ('adasyn', param_ADASYN),\n",
    "                                                  ('no_spl', {'spl': ['passthrough']})]:\n",
    "        param_grid = {**param_vectorizer,\n",
    "                      **{f\"{key}\": value for key, value in oversampler_params.items()},\n",
    "                      **param}\n",
    "        param_grids.append(param_grid)\n",
    "\n",
    "    bscv = searchCV(X_train, y_gp_train_encoded, pipeline, param_grids)\n",
    "    cvinstances.append((pipeline[0], bscv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3cb5f39a5fbb97",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Rebuild models with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4a73c8ef002",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    (\n",
    "        'SGDLogisticRegression',\n",
    "        Pipeline([\n",
    "            ('vect', TfidfVectorizer(max_df=0.9679849809437826, max_features=26641, min_df=0.0, ngram_range=(1, 1))),\n",
    "            ('clf', SGDClassifier(\n",
    "                alpha=0.0001,\n",
    "                class_weight='balanced',\n",
    "                eta0=0.05000915524973822,\n",
    "                l1_ratio=0.1420892145814889,\n",
    "                learning_rate='optimal',\n",
    "                loss='log_loss',\n",
    "                max_iter=3163,\n",
    "                n_jobs=-1,\n",
    "                penalty='elasticnet',\n",
    "                random_state=3013,\n",
    "            ))\n",
    "        ])\n",
    "    ),\n",
    "    (\n",
    "        'SGDLinearSVM',\n",
    "        Pipeline([ \n",
    "            ('vect', TfidfVectorizer(max_df=1, max_features=22119, min_df=0.0, ngram_range=(1, 3))),\n",
    "            ('clf', CalibratedClassifierCV(\n",
    "                base_estimator=SGDClassifier(\n",
    "                    alpha=0.0001,\n",
    "                    class_weight=None,\n",
    "                    eta0=0.02558639455287378,\n",
    "                    l1_ratio=0.47339370383296875,\n",
    "                    learning_rate='adaptive',\n",
    "                    loss='hinge',\n",
    "                    max_iter=5000,\n",
    "                    penalty='l2',\n",
    "                    random_state=3013,\n",
    "                    n_jobs=-1,\n",
    "                ),\n",
    "                cv=10,\n",
    "                method='isotonic'\n",
    "            ))\n",
    "        ])\n",
    "    ),\n",
    "    (\n",
    "        'LGBMClassifier',\n",
    "        Pipeline([\n",
    "            ('vect', TfidfVectorizer(max_df=0.980786564471343, max_features=50000, min_df=0.0)),\n",
    "            ('spl', SMOTE(\n",
    "                sampling_strategy='not majority',\n",
    "                random_state=3013,\n",
    "                k_neighbors=cuNN(n_neighbors=10, n_jobs=-1),\n",
    "            )),\n",
    "            ('clf', LGBMClassifier(\n",
    "                bagging_fraction=0.99,\n",
    "                bagging_freq=4,\n",
    "                boosting_type='dart',\n",
    "                class_weight=None,\n",
    "                feature_fraction=0.99,\n",
    "                learning_rate=0.1736279711857161,\n",
    "                n_estimators=123,\n",
    "                n_jobs=-1,\n",
    "                num_iterations=117,\n",
    "                num_leaves=60,\n",
    "                random_state=3013\n",
    "            ))\n",
    "        ])\n",
    "    )\n",
    "]\n",
    "\n",
    "voting_classifier = EnsembleVoteClassifier(clfs=[clf[1] for clf in classifiers], voting='soft',\n",
    "                                           fit_base_estimators=False)\n",
    "\n",
    "classifiers.append(('Voting Classifier', voting_classifier))\n",
    "\n",
    "evaluate_model(X_train, X_test, y_gp_train_encoded, y_gp_test_encoded, gp_encoder, classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca43aeddac8592",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b2887eb569c42",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model_name = 'Voting Classifier'\n",
    "\n",
    "best_model = next((classifier for name, classifier in classifiers if name == best_model_name), None)\n",
    "\n",
    "dump(best_model, 'best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca7861ebbf094f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7cfc2212de17b4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = input('Enter text for emotion classification: ')\n",
    "\n",
    "emo_clf = load('best_model.joblib')\n",
    "emo_clf.predict([preprocess_text('text')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc49f2068c1e2f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Intent Classification using Rasa DIETClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbddddcb5b28a109",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model training with intents data in [nlu.yml](/data/nlu.yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47029a4ab1fc491",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-05T19:00:15.890581100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install rasa\n",
    "!rasa init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f238561c79c11b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rasa train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6858fc32ee6310",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a5cb244e792b44",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rasa.core.agent import Agent\n",
    "from rasa.core\n",
    "\n",
    "nlu_interpreter = Agent.load(\"/content/drive/MyDrive/PROJECT_PATTERN/models/20240203-225351-fast-median.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e791c19d3dc4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rasa.model import get_latest_model\n",
    "from rasa.cli.utils import get_validated_path\n",
    "from rasa.cli.scaffold import create_initial_project\n",
    "\n",
    "model = get_latest_model('/models')\n",
    "\n",
    "\n",
    "# Define a function to get the response\n",
    "def get_rasa_response(user_input):\n",
    "    interpreter = model.get_interpreter()\n",
    "    response = interpreter.parse_message(user_input)\n",
    "    return response['text']\n",
    "\n",
    "\n",
    "# Example usage\n",
    "user_input = \"Hello, how are you?\"\n",
    "rasa_response = get_rasa_response(user_input)\n",
    "print(\"Assistant:\", rasa_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448107cc3f0357a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify_intent(text):\n",
    "    return await nlu_interpreter.parse_message(message_data=text)['intent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07188fa9e412516",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(classify_intent(input('Enter input')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf6193c76785d9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Response generation based on ChatGPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6408f4af217cdc7f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"YOUR_KEY\"\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb29a428e68ed131",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateResponse(emotion, intent, ori_text, user_info, suggestion_reply=None):\n",
    "    content = json.dumps(\n",
    "        {'emotion': emotion, 'intent': intent, 'user_input': ori_text, 'suggestion_reply': suggestion_reply,\n",
    "         'user_info': user_info})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"You are a supportive virtual counseling assistant, empathetic and understanding. Your goal is to assist users in expressing their feelings, providing guidance, and offering a comforting presence.\"},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ebcfee6fb0288f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Frontend for Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8352108a0fdc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ngrok authtoken '2YgweMYFLveRiLfPxFkJPnCAQxo_5K6Y6536DzswvQgZfBHDW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0939a5938206ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from flask import render_template, Flask, request\n",
    "from flask_ngrok import run_with_ngrok\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "run_with_ngrok(app)\n",
    "\n",
    "avatars = [\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Bear&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Fluffy&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Jasmine&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Sassy&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Angel&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Boots&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Cookie&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Gizmo&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Leo&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Whiskers&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Midnight&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Willow&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Maggie&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Misty&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Gracie&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Pumpkin&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Pepper&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Boo&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf',\n",
    "    'https://api.dicebear.com/7.x/bottts/svg?seed=Cali&scale=90&backgroundColor=b6e3f4,c0aede,d1d4f9,ffd5dc,ffdfbf'\n",
    "]\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template('index.html', avatars=avatars)\n",
    "\n",
    "\n",
    "@app.route('/get_response', methods=['POST'])\n",
    "def get_response():\n",
    "    data = request.get_json()\n",
    "    text = data['text']\n",
    "    profile = data['profile']\n",
    "    intent = classify_intent(text)\n",
    "    emotion = emo_clf.predict(preprocess_text(text))\n",
    "    return generateResponse(emotion, intent, text, profile)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
